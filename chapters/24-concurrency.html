<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Concurrency Fundamentals - Rust Universe: Fearless Systems Engineering</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="A comprehensive guide to learning the Rust programming language from fundamentals to mastery.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../theme/custom.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 1: Fundamentals</li><li class="chapter-item expanded "><a href="../chapters/01-about-this-book.html"><strong aria-hidden="true">1.</strong> About This Book</a></li><li class="chapter-item expanded "><a href="../chapters/02-introduction-to-rust.html"><strong aria-hidden="true">2.</strong> Introduction to Rust</a></li><li class="chapter-item expanded "><a href="../chapters/03-getting-started.html"><strong aria-hidden="true">3.</strong> Getting Started with the Rust Toolchain</a></li><li class="chapter-item expanded "><a href="../chapters/04-basic-syntax.html"><strong aria-hidden="true">4.</strong> Basic Syntax and Data Types</a></li><li class="chapter-item expanded "><a href="../chapters/05-control-flow.html"><strong aria-hidden="true">5.</strong> Control Flow in Rust</a></li><li class="chapter-item expanded "><a href="../chapters/06-functions.html"><strong aria-hidden="true">6.</strong> Functions and Procedures</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 2: Ownership - Rust's Secret Weapon</li><li class="chapter-item expanded "><a href="../chapters/07-understanding-ownership.html"><strong aria-hidden="true">7.</strong> Understanding Ownership</a></li><li class="chapter-item expanded "><a href="../chapters/08-borrowing-references.html"><strong aria-hidden="true">8.</strong> Borrowing and References</a></li><li class="chapter-item expanded "><a href="../chapters/09-strings-slices.html"><strong aria-hidden="true">9.</strong> Working with Strings and Slices</a></li><li class="chapter-item expanded "><a href="../chapters/10-advanced-ownership.html"><strong aria-hidden="true">10.</strong> Advanced Ownership Patterns</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 3: Organizing Code</li><li class="chapter-item expanded "><a href="../chapters/11-structs.html"><strong aria-hidden="true">11.</strong> Structs and Custom Types</a></li><li class="chapter-item expanded "><a href="../chapters/12-enums.html"><strong aria-hidden="true">12.</strong> Enums and Pattern Matching</a></li><li class="chapter-item expanded "><a href="../chapters/13-modules.html"><strong aria-hidden="true">13.</strong> Modules and Organizing Code</a></li><li class="chapter-item expanded "><a href="../chapters/14-collections.html"><strong aria-hidden="true">14.</strong> Collections and Data Structures</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 4: Generic Programming</li><li class="chapter-item expanded "><a href="../chapters/15-generics.html"><strong aria-hidden="true">15.</strong> Introduction to Generics</a></li><li class="chapter-item expanded "><a href="../chapters/16-traits.html"><strong aria-hidden="true">16.</strong> Traits and Polymorphism</a></li><li class="chapter-item expanded "><a href="../chapters/17-advanced-traits.html"><strong aria-hidden="true">17.</strong> Advanced Trait Patterns</a></li><li class="chapter-item expanded "><a href="../chapters/18-lifetimes.html"><strong aria-hidden="true">18.</strong> Understanding Lifetimes</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 5: Error Handling</li><li class="chapter-item expanded "><a href="../chapters/19-panic.html"><strong aria-hidden="true">19.</strong> Panic and Unrecoverable Errors</a></li><li class="chapter-item expanded "><a href="../chapters/20-result-option.html"><strong aria-hidden="true">20.</strong> Result, Option, and Recoverable Errors</a></li><li class="chapter-item expanded "><a href="../chapters/21-error-patterns.html"><strong aria-hidden="true">21.</strong> Error Handling Patterns and Libraries</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 6: Advanced Rust</li><li class="chapter-item expanded "><a href="../chapters/22-iterators.html"><strong aria-hidden="true">22.</strong> Iterators and Functional Programming</a></li><li class="chapter-item expanded "><a href="../chapters/23-closures.html"><strong aria-hidden="true">23.</strong> Closures in Depth</a></li><li class="chapter-item expanded "><a href="../chapters/24-concurrency.html" class="active"><strong aria-hidden="true">24.</strong> Concurrency Fundamentals</a></li><li class="chapter-item expanded "><a href="../chapters/25-async.html"><strong aria-hidden="true">25.</strong> Asynchronous Programming</a></li><li class="chapter-item expanded "><a href="../chapters/26-macros.html"><strong aria-hidden="true">26.</strong> Macros and Metaprogramming</a></li><li class="chapter-item expanded "><a href="../chapters/27-unsafe.html"><strong aria-hidden="true">27.</strong> Unsafe Rust</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 7: Practical Rust</li><li class="chapter-item expanded "><a href="../chapters/28-testing.html"><strong aria-hidden="true">28.</strong> Writing Tests in Rust</a></li><li class="chapter-item expanded "><a href="../chapters/29-cli.html"><strong aria-hidden="true">29.</strong> Command-Line Applications</a></li><li class="chapter-item expanded "><a href="../chapters/30-web.html"><strong aria-hidden="true">30.</strong> Web Development with Rust</a></li><li class="chapter-item expanded "><a href="../chapters/31-database.html"><strong aria-hidden="true">31.</strong> Database Interaction</a></li><li class="chapter-item expanded "><a href="../chapters/32-network.html"><strong aria-hidden="true">32.</strong> Network Programming</a></li><li class="chapter-item expanded "><a href="../chapters/33-systems.html"><strong aria-hidden="true">33.</strong> Systems Programming</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 8: The Rust Ecosystem</li><li class="chapter-item expanded "><a href="../chapters/34-cargo.html"><strong aria-hidden="true">34.</strong> Package Management with Cargo</a></li><li class="chapter-item expanded "><a href="../chapters/35-build-systems.html"><strong aria-hidden="true">35.</strong> Build Systems and Tooling</a></li><li class="chapter-item expanded "><a href="../chapters/36-performance.html"><strong aria-hidden="true">36.</strong> Performance Optimization</a></li><li class="chapter-item expanded "><a href="../chapters/37-interoperability.html"><strong aria-hidden="true">37.</strong> Interoperability with Other Languages</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 9: Modern Rust Applications</li><li class="chapter-item expanded "><a href="../chapters/38-database-building.html"><strong aria-hidden="true">38.</strong> Building a Database</a></li><li class="chapter-item expanded "><a href="../chapters/39-game-development.html"><strong aria-hidden="true">39.</strong> Game Development</a></li><li class="chapter-item expanded "><a href="../chapters/40-cloud-native.html"><strong aria-hidden="true">40.</strong> Cloud Native Rust</a></li><li class="chapter-item expanded "><a href="../chapters/41-distributed-systems.html"><strong aria-hidden="true">41.</strong> Distributed Systems</a></li><li class="chapter-item expanded "><a href="../chapters/42-machine-learning.html"><strong aria-hidden="true">42.</strong> Machine Learning and Data Science</a></li><li class="chapter-item expanded "><a href="../chapters/43-embedded.html"><strong aria-hidden="true">43.</strong> Embedded Systems and IoT</a></li><li class="chapter-item expanded "><a href="../chapters/44-production-ready.html"><strong aria-hidden="true">44.</strong> Production-Ready Rust</a></li><li class="chapter-item expanded affix "><li class="part-title">Section 10: Capstone Projects</li><li class="chapter-item expanded "><a href="../chapters/45-search-engine.html"><strong aria-hidden="true">45.</strong> Building a Search Engine</a></li><li class="chapter-item expanded "><a href="../chapters/46-programming-language.html"><strong aria-hidden="true">46.</strong> Developing a Programming Language</a></li><li class="chapter-item expanded "><a href="../chapters/47-blockchain.html"><strong aria-hidden="true">47.</strong> Creating a Blockchain Application</a></li><li class="chapter-item expanded "><a href="../chapters/48-data-processing.html"><strong aria-hidden="true">48.</strong> Real-Time Data Processing System</a></li><li class="chapter-item expanded "><a href="../chapters/49-wasm-frontend.html"><strong aria-hidden="true">49.</strong> WebAssembly and Frontend Development</a></li><li class="chapter-item expanded "><a href="../chapters/50-advanced-memory.html"><strong aria-hidden="true">50.</strong> Advanced Memory Management</a></li><li class="chapter-item expanded "><a href="../chapters/51-edge-computing.html"><strong aria-hidden="true">51.</strong> Rust for Edge Computing</a></li><li class="chapter-item expanded "><a href="../chapters/52-security.html"><strong aria-hidden="true">52.</strong> Rust Security Patterns and Auditing</a></li><li class="chapter-item expanded affix "><li class="part-title">Appendices</li><li class="chapter-item expanded "><a href="../appendices/a-idioms-patterns.html"><strong aria-hidden="true">53.</strong> Common Rust Idioms and Patterns</a></li><li class="chapter-item expanded "><a href="../appendices/b-rust-evolution.html"><strong aria-hidden="true">54.</strong> Rust's Evolution: Editions and Features</a></li><li class="chapter-item expanded "><a href="../appendices/c-language-comparison.html"><strong aria-hidden="true">55.</strong> Comparison with Other Languages</a></li><li class="chapter-item expanded "><a href="../appendices/d-recommended-libraries.html"><strong aria-hidden="true">56.</strong> Recommended Libraries and Crates</a></li><li class="chapter-item expanded "><a href="../appendices/e-memory-model.html"><strong aria-hidden="true">57.</strong> Rust's Memory Model In-Depth</a></li><li class="chapter-item expanded "><a href="../appendices/f-community-resources.html"><strong aria-hidden="true">58.</strong> Community Resources and Contribution Guide</a></li><li class="chapter-item expanded "><a href="../appendices/g-debugging.html"><strong aria-hidden="true">59.</strong> Debugging and Troubleshooting Guide</a></li><li class="chapter-item expanded "><a href="../appendices/h-optimization-cookbook.html"><strong aria-hidden="true">60.</strong> Performance Optimization Cookbook</a></li><li class="chapter-item expanded "><a href="../appendices/i-glossary.html"><strong aria-hidden="true">61.</strong> Comprehensive Glossary</a></li><li class="chapter-item expanded "><a href="../appendices/j-learning-paths.html"><strong aria-hidden="true">62.</strong> Learning Paths for Different Backgrounds</a></li><li class="chapter-item expanded "><a href="../appendices/k-interview-questions.html"><strong aria-hidden="true">63.</strong> Interview Questions and Answers</a></li><li class="chapter-item expanded "><a href="../appendices/l-resources.html"><strong aria-hidden="true">64.</strong> Recommended Reading and Resources</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Rust Universe: Fearless Systems Engineering</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/saeedalam/rust-universe" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/saeedalam/rust-universe/edit/main/src/chapters/24-concurrency.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="chapter-24-concurrency-fundamentals"><a class="header" href="#chapter-24-concurrency-fundamentals">Chapter 24: Concurrency Fundamentals</a></h1>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>Concurrency is a foundational concept in modern programming, enabling software to effectively utilize multi-core processors and handle multiple tasks simultaneously. Rust's approach to concurrency is one of its most distinctive features—it provides powerful concurrency primitives while enforcing safety at compile time through its ownership system.</p>
<p>Unlike many other languages where concurrency bugs can lurk until runtime, Rust's compiler prevents data races and many other concurrency hazards before your program even runs. The mantra &quot;fearless concurrency&quot; aptly describes how Rust empowers developers to write concurrent code with confidence.</p>
<p>In this chapter, we'll explore Rust's concurrency model from the ground up. We'll start with the fundamental building blocks of threads, move through various synchronization mechanisms, and build toward more sophisticated concurrency patterns. By the end, you'll understand not only how to write concurrent Rust code, but also why Rust's approach to concurrency is revolutionizing how we think about parallel programming.</p>
<p>Whether you're building high-performance servers, data processing pipelines, or responsive user interfaces, the skills you learn in this chapter will help you write code that effectively harnesses the full power of modern hardware while maintaining Rust's guarantees of safety and reliability.</p>
<h2 id="understanding-concurrency-vs-parallelism"><a class="header" href="#understanding-concurrency-vs-parallelism">Understanding Concurrency vs Parallelism</a></h2>
<p>Before diving into Rust's concurrency features, it's essential to understand the distinction between concurrency and parallelism—related concepts that are often confused.</p>
<h3 id="concurrency-dealing-with-multiple-tasks"><a class="header" href="#concurrency-dealing-with-multiple-tasks">Concurrency: Dealing with Multiple Tasks</a></h3>
<p>Concurrency refers to the ability to handle multiple tasks in overlapping time periods. It's about the structure of a program—how it's composed of independently executing processes. A concurrent program has multiple logical threads of control, but those threads might not be executing simultaneously.</p>
<p>Think of concurrency as juggling multiple balls. You're not literally handling all the balls at the same time; you're quickly switching between them, ensuring that each ball gets enough attention to stay in the air.</p>
<h3 id="parallelism-doing-multiple-tasks-simultaneously"><a class="header" href="#parallelism-doing-multiple-tasks-simultaneously">Parallelism: Doing Multiple Tasks Simultaneously</a></h3>
<p>Parallelism, on the other hand, is about execution. A parallel program actively executes multiple tasks at the exact same time, typically on different processor cores. Parallelism requires hardware with multiple processing units.</p>
<p>To extend our analogy, parallelism is like having multiple jugglers, each handling their own balls independently.</p>
<h3 id="the-relationship-between-concurrency-and-parallelism"><a class="header" href="#the-relationship-between-concurrency-and-parallelism">The Relationship Between Concurrency and Parallelism</a></h3>
<p>Concurrency is about structure; parallelism is about execution. A program can be concurrent without being parallel (executing on a single core by interleaving tasks), but parallelism requires some form of concurrency in the program's design.</p>
<p>Here's a simple example to illustrate the difference:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;
use std::time::Duration;

fn main() {
    // This is concurrent but may not be parallel
    // (depending on your system and the OS scheduler)
    let handle1 = thread::spawn(|| {
        for i in 1..=5 {
            println!(&quot;Thread 1: {}&quot;, i);
            thread::sleep(Duration::from_millis(500));
        }
    });

    let handle2 = thread::spawn(|| {
        for i in 1..=5 {
            println!(&quot;Thread 2: {}&quot;, i);
            thread::sleep(Duration::from_millis(500));
        }
    });

    // Wait for both threads to complete
    handle1.join().unwrap();
    handle2.join().unwrap();
}</code></pre></pre>
<p>Running this program on a multi-core system will likely result in parallel execution, with both threads running simultaneously on different cores. On a single-core system, the threads would still be concurrent, but the CPU would rapidly switch between them to create the illusion of parallelism.</p>
<h3 id="why-this-distinction-matters-in-rust"><a class="header" href="#why-this-distinction-matters-in-rust">Why This Distinction Matters in Rust</a></h3>
<p>Rust's concurrency model is designed to address both concurrency and parallelism effectively:</p>
<ol>
<li>
<p><strong>Concurrency Safety</strong>: Rust's ownership system prevents data races at compile time, making concurrent programming safer.</p>
</li>
<li>
<p><strong>Parallelism Efficiency</strong>: Rust's zero-cost abstractions ensure that concurrent code can be efficiently parallelized without runtime overhead.</p>
</li>
<li>
<p><strong>Scalability</strong>: Rust programs can seamlessly scale from single-core to multi-core execution without changing the underlying safety guarantees.</p>
</li>
</ol>
<p>In the following sections, we'll explore how Rust implements these concepts through threads, synchronization primitives, and message passing.</p>
<h2 id="threads-and-threadspawn"><a class="header" href="#threads-and-threadspawn">Threads and thread::spawn</a></h2>
<p>At the foundation of Rust's concurrency model are threads—independent sequences of execution that can run concurrently within a program. Rust provides a native threading API through the <code>std::thread</code> module.</p>
<h3 id="creating-threads-with-spawn"><a class="header" href="#creating-threads-with-spawn">Creating Threads with spawn</a></h3>
<p>The most basic way to create a thread in Rust is with <code>thread::spawn</code>, which takes a closure containing the code to be executed in the new thread:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;

fn main() {
    // Spawn a new thread
    let handle = thread::spawn(|| {
        // This code runs in a new thread
        println!(&quot;Hello from a thread!&quot;);
    });

    // This code runs in the main thread
    println!(&quot;Hello from the main thread!&quot;);

    // Wait for the spawned thread to finish
    handle.join().unwrap();
}</code></pre></pre>
<p>The <code>spawn</code> function returns a <code>JoinHandle</code>, which we can use to wait for the thread to finish or perform other operations on the thread.</p>
<h3 id="joining-threads"><a class="header" href="#joining-threads">Joining Threads</a></h3>
<p>The <code>join</code> method on a <code>JoinHandle</code> blocks the current thread until the thread associated with the handle terminates. This is important for ensuring that a spawned thread completes its work before the program exits:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;
use std::time::Duration;

fn main() {
    let handle = thread::spawn(|| {
        // Simulate a long-running operation
        thread::sleep(Duration::from_secs(2));
        println!(&quot;Thread finished!&quot;);
    });

    println!(&quot;Waiting for thread to finish...&quot;);

    // Block until the thread completes
    handle.join().unwrap();

    println!(&quot;Main thread continuing after join&quot;);
}</code></pre></pre>
<p>If you don't call <code>join()</code>, the main thread might finish and exit the program before the spawned thread has a chance to complete its work.</p>
<h3 id="thread-return-values"><a class="header" href="#thread-return-values">Thread Return Values</a></h3>
<p>Threads can return values, which become available when <code>join()</code> is called:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;

fn main() {
    let handle = thread::spawn(|| {
        // Perform some calculation
        let result = 42;

        // Return the result from the thread
        result
    });

    // Retrieve the thread's return value
    let result = handle.join().unwrap();
    println!(&quot;Thread returned: {}&quot;, result);
}</code></pre></pre>
<p>The <code>join</code> method returns a <code>Result&lt;T&gt;</code> where <code>T</code> is the return type of the thread's closure. If the thread panicked, <code>join</code> will return an <code>Err</code> containing the panic payload.</p>
<h3 id="capturing-environment-with-move"><a class="header" href="#capturing-environment-with-move">Capturing Environment with move</a></h3>
<p>Closures passed to <code>thread::spawn</code> often need to access variables from their enclosing scope. However, due to Rust's ownership rules, the closure must take ownership of any values it references from the surrounding environment. This is where the <code>move</code> keyword comes in:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;

fn main() {
    let message = String::from(&quot;Hello from a captured variable!&quot;);

    // Use move to transfer ownership of message to the thread
    let handle = thread::spawn(move || {
        println!(&quot;{}&quot;, message);
    });

    // Can't use message here anymore because ownership was transferred
    // println!(&quot;{}&quot;, message); // This would cause a compilation error

    handle.join().unwrap();
}</code></pre></pre>
<p>Without the <code>move</code> keyword, the closure would try to borrow <code>message</code>, but the compiler can't guarantee that the main thread won't invalidate this reference before or during the spawned thread's execution.</p>
<h3 id="thread-builder"><a class="header" href="#thread-builder">Thread Builder</a></h3>
<p>For more control over thread creation, Rust provides the <code>Builder</code> API:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;

fn main() {
    let builder = thread::Builder::new()
        .name(&quot;custom-thread&quot;.into())
        .stack_size(32 * 1024); // 32KB stack

    let handle = builder.spawn(|| {
        println!(&quot;Running in thread named: {:?}&quot;, thread::current().name());
    }).unwrap();

    handle.join().unwrap();
}</code></pre></pre>
<p>The <code>Builder</code> allows you to customize various aspects of the thread, such as its name and stack size, before spawning it.</p>
<h3 id="current-thread-and-thread-local-storage"><a class="header" href="#current-thread-and-thread-local-storage">Current Thread and Thread-Local Storage</a></h3>
<p>Rust provides ways to access the current thread and store thread-local data:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;
use std::cell::RefCell;

thread_local! {
    static COUNTER: RefCell&lt;u32&gt; = RefCell::new(0);
}

fn main() {
    let handle1 = thread::spawn(|| {
        COUNTER.with(|counter| {
            *counter.borrow_mut() += 1;
            println!(&quot;Thread 1: counter = {}&quot;, *counter.borrow());
        });
    });

    let handle2 = thread::spawn(|| {
        COUNTER.with(|counter| {
            *counter.borrow_mut() += 1;
            println!(&quot;Thread 2: counter = {}&quot;, *counter.borrow());
        });
    });

    handle1.join().unwrap();
    handle2.join().unwrap();

    COUNTER.with(|counter| {
        println!(&quot;Main thread: counter = {}&quot;, *counter.borrow());
    });
}</code></pre></pre>
<p>Each thread gets its own independent copy of the thread-local storage, which can be useful for tracking per-thread state without synchronization overhead.</p>
<h3 id="thread-parking"><a class="header" href="#thread-parking">Thread Parking</a></h3>
<p>Rust provides mechanisms to temporarily suspend and resume thread execution:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;
use std::time::Duration;

fn main() {
    let handle = thread::spawn(|| {
        println!(&quot;Thread going to park&quot;);
        thread::park();
        println!(&quot;Thread unparked and continuing&quot;);
    });

    // Give the thread time to park
    thread::sleep(Duration::from_millis(500));

    // Unpark the thread
    handle.thread().unpark();
    handle.join().unwrap();
}</code></pre></pre>
<p>The <code>park</code> method suspends the current thread until it is unparked, which can be useful for implementing condition variables and other synchronization primitives.</p>
<h2 id="thread-safety-guarantees"><a class="header" href="#thread-safety-guarantees">Thread Safety Guarantees</a></h2>
<p>One of Rust's most celebrated features is its ability to prevent data races at compile time. This is achieved through a combination of the ownership system, type system, and trait system, which together enforce thread safety.</p>
<h3 id="data-races-and-why-they-matter"><a class="header" href="#data-races-and-why-they-matter">Data Races and Why They Matter</a></h3>
<p>A data race occurs when:</p>
<ol>
<li>Two or more threads access the same memory location concurrently</li>
<li>At least one of the accesses is a write</li>
<li>There's no synchronization mechanism controlling the accesses</li>
</ol>
<p>Data races lead to undefined behavior, which can manifest as subtle and hard-to-reproduce bugs, crashes, or security vulnerabilities.</p>
<h3 id="how-rust-prevents-data-races"><a class="header" href="#how-rust-prevents-data-races">How Rust Prevents Data Races</a></h3>
<p>Rust prevents data races through its type system, specifically with the <code>Send</code> and <code>Sync</code> traits:</p>
<ul>
<li><strong><code>Send</code></strong>: Types that can be safely transferred between threads</li>
<li><strong><code>Sync</code></strong>: Types that can be safely shared between threads (via references)</li>
</ul>
<p>The compiler enforces these traits automatically, preventing you from sharing data between threads unless it's safe to do so.</p>
<h3 id="the-send-trait"><a class="header" href="#the-send-trait">The Send Trait</a></h3>
<p>A type is <code>Send</code> if it's safe to transfer ownership of values of that type between threads. Most Rust types are <code>Send</code>, with a few notable exceptions:</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;
use std::rc::Rc;

fn main() {
    let data = Rc::new(42); // Rc is not Send

    // This would fail to compile:
    // let handle = thread::spawn(move || {
    //     println!(&quot;The answer is: {}&quot;, *data);
    // });

    // Instead, we can use Arc, which is Send:
    let data = std::sync::Arc::new(42);

    let handle = thread::spawn(move || {
        println!(&quot;The answer is: {}&quot;, *data);
    });

    handle.join().unwrap();
}</code></pre></pre>
<p><code>Rc</code> (Reference Counted) is not thread-safe and thus not <code>Send</code>. Attempting to move it across thread boundaries will result in a compilation error. <code>Arc</code> (Atomic Reference Counted) is the thread-safe alternative.</p>
<h3 id="the-sync-trait"><a class="header" href="#the-sync-trait">The Sync Trait</a></h3>
<p>A type is <code>Sync</code> if it's safe to share references to values of that type between threads. Mathematically, a type <code>T</code> is <code>Sync</code> if and only if <code>&amp;T</code> is <code>Send</code>.</p>
<pre><pre class="playground"><code class="language-rust">use std::thread;
use std::cell::RefCell;
use std::sync::{Arc, Mutex};

fn main() {
    // RefCell is not Sync
    let data = Arc::new(RefCell::new(42));

    // This would fail to compile:
    // let handle = thread::spawn(move || {
    //     *data.borrow_mut() += 1;
    // });

    // Instead, we can use Mutex, which is Sync:
    let data = Arc::new(Mutex::new(42));

    let handle = thread::spawn(move || {
        let mut value = data.lock().unwrap();
        *value += 1;
    });

    handle.join().unwrap();
    println!(&quot;Final value: {}&quot;, *data.lock().unwrap());
}</code></pre></pre>
<p><code>RefCell</code> provides interior mutability, but it's not thread-safe and thus not <code>Sync</code>. <code>Mutex</code> is the thread-safe alternative that provides similar functionality.</p>
<h3 id="implementing-send-and-sync"><a class="header" href="#implementing-send-and-sync">Implementing Send and Sync</a></h3>
<p>Most types automatically implement <code>Send</code> and <code>Sync</code> based on their constituent parts. However, you can explicitly implement (or not implement) these traits:</p>
<pre><pre class="playground"><code class="language-rust">use std::marker::{Send, Sync};

// A type that is not thread-safe by default
struct MyNonThreadSafeType {
    data: u32,
}

// Mark it as Send and Sync (unsafe because we're promising
// the compiler that our type is thread-safe)
unsafe impl Send for MyNonThreadSafeType {}
unsafe impl Sync for MyNonThreadSafeType {}

fn main() {
    let data = MyNonThreadSafeType { data: 42 };

    let handle = std::thread::spawn(move || {
        println!(&quot;Data in thread: {}&quot;, data.data);
    });

    handle.join().unwrap();
}</code></pre></pre>
<p>This is an unsafe operation because you're bypassing Rust's safety checks. Only do this if you're absolutely certain your type is thread-safe and you understand the concurrency implications.</p>
<h3 id="thread-safety-at-the-type-level"><a class="header" href="#thread-safety-at-the-type-level">Thread Safety at the Type Level</a></h3>
<p>Rust's approach to thread safety is unique because it's enforced at the type level, during compilation. This means:</p>
<ol>
<li>Thread safety bugs are caught before your program runs</li>
<li>There's no runtime overhead for these checks</li>
<li>The compiler can optimize code knowing certain race conditions are impossible</li>
</ol>
<p>This type-level approach is what enables &quot;fearless concurrency&quot; in Rust—you can write concurrent code with confidence, knowing that many common concurrency bugs are impossible by design.</p>
<h2 id="race-conditions-and-data-races"><a class="header" href="#race-conditions-and-data-races">Race Conditions and Data Races</a></h2>
<p>When writing concurrent code, there are two related but distinct problems that can arise: race conditions and data races. Understanding the difference is crucial for writing correct concurrent programs.</p>
<h3 id="what-is-a-data-race"><a class="header" href="#what-is-a-data-race">What is a Data Race?</a></h3>
<p>A data race occurs when:</p>
<ol>
<li>Two or more threads access the same memory location concurrently</li>
<li>At least one of the accesses is a write</li>
<li>There's no synchronization mechanism controlling the accesses</li>
</ol>
<p>Data races lead to undefined behavior in languages like C and C++. In Rust, the type system prevents data races at compile time, making them impossible in safe code.</p>
<h3 id="what-is-a-race-condition"><a class="header" href="#what-is-a-race-condition">What is a Race Condition?</a></h3>
<p>A race condition is a broader concept than a data race. It occurs when the correctness of a program depends on the relative timing or interleaving of multiple threads or processes. Even with proper synchronization that prevents data races, race conditions can still occur.</p>
<h3 id="an-example-of-a-race-condition"><a class="header" href="#an-example-of-a-race-condition">An Example of a Race Condition</a></h3>
<p>Let's look at a simple example that demonstrates a race condition but not a data race:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter = Arc::clone(&amp;counter);
        let handle = thread::spawn(move || {
            // Get the current value
            let current = *counter.lock().unwrap();

            // Simulate some work
            thread::sleep(std::time::Duration::from_millis(1));

            // Update with current + 1
            *counter.lock().unwrap() = current + 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Final count: {}&quot;, *counter.lock().unwrap());
}</code></pre></pre>
<p>This code has a race condition but not a data race. The <code>Mutex</code> prevents data races by ensuring that only one thread can access the counter at a time. However, there's still a race condition because:</p>
<ol>
<li>A thread reads the current value</li>
<li>It then releases the lock</li>
<li>Other threads may modify the value</li>
<li>When the original thread re-acquires the lock and writes, it's based on a stale value</li>
</ol>
<p>This is a classic &quot;check-then-act&quot; race condition. The solution is to hold the lock across both the read and write operations:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter = Arc::clone(&amp;counter);
        let handle = thread::spawn(move || {
            // Acquire the lock once and keep it until we're done
            let mut value = counter.lock().unwrap();

            // Simulate some work
            thread::sleep(std::time::Duration::from_millis(1));

            // Update the value while still holding the lock
            *value += 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Final count: {}&quot;, *counter.lock().unwrap());
}</code></pre></pre>
<h3 id="atomicity-and-ordering"><a class="header" href="#atomicity-and-ordering">Atomicity and Ordering</a></h3>
<p>Race conditions often involve issues of atomicity (operations that must be performed as a single, indivisible unit) and ordering (the sequence in which operations occur).</p>
<p>Rust provides atomic types in the <code>std::sync::atomic</code> module that can help with certain types of race conditions:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::atomic::{AtomicUsize, Ordering};
use std::thread;

fn main() {
    let counter = AtomicUsize::new(0);
    let mut handles = vec![];

    for _ in 0..10 {
        let handle = thread::spawn(move || {
            for _ in 0..1000 {
                // Atomically increment the counter
                counter.fetch_add(1, Ordering::SeqCst);
            }
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Final count: {}&quot;, counter.load(Ordering::SeqCst));
}</code></pre></pre>
<p>This won't compile because <code>counter</code> is not shared between threads. Let's fix that:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::thread;

fn main() {
    let counter = Arc::new(AtomicUsize::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter = Arc::clone(&amp;counter);
        let handle = thread::spawn(move || {
            for _ in 0..1000 {
                // Atomically increment the counter
                counter.fetch_add(1, Ordering::SeqCst);
            }
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Final count: {}&quot;, counter.load(Ordering::SeqCst));
}</code></pre></pre>
<h3 id="detecting-race-conditions"><a class="header" href="#detecting-race-conditions">Detecting Race Conditions</a></h3>
<p>Unlike data races, which Rust prevents at compile time, race conditions can still occur in Rust programs and can be difficult to detect. Here are some strategies to identify and fix race conditions:</p>
<ol>
<li><strong>Code reviews</strong>: Carefully examine concurrent code for potential race conditions</li>
<li><strong>Testing</strong>: Use stress testing with many threads and iterations</li>
<li><strong>Thread sanitizers</strong>: Tools like TSAN (though support in Rust is still developing)</li>
<li><strong>Formal verification</strong>: For critical systems, consider formal verification techniques</li>
</ol>
<h3 id="debugging-race-conditions"><a class="header" href="#debugging-race-conditions">Debugging Race Conditions</a></h3>
<p>Race conditions can be notoriously difficult to debug because they depend on specific timing and may not reproduce consistently. Here are some tips for debugging race conditions in Rust:</p>
<ol>
<li><strong>Add logging</strong>: Detailed logging can help understand the sequence of events</li>
<li><strong>Simplify</strong>: Reduce the code to the minimal example that still shows the issue</li>
<li><strong>Force specific interleavings</strong>: Add sleeps or other delays to try to trigger the race condition consistently</li>
<li><strong>Use thread-safe data structures</strong>: Replace your custom synchronization with proven thread-safe abstractions</li>
</ol>
<h2 id="sharing-state-with-mutex-and-arc"><a class="header" href="#sharing-state-with-mutex-and-arc">Sharing State with Mutex and Arc</a></h2>
<p>Safe concurrent programming often requires sharing state between threads. Rust provides several tools for this, with <code>Mutex</code> and <code>Arc</code> being among the most important.</p>
<h3 id="mutex-mutual-exclusion"><a class="header" href="#mutex-mutual-exclusion">Mutex: Mutual Exclusion</a></h3>
<p>A mutex (mutual exclusion) ensures that only one thread can access a piece of data at a time. In Rust, the <code>Mutex&lt;T&gt;</code> type wraps a value of type <code>T</code> and ensures exclusive access.</p>
<p>Here's a basic example:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::Mutex;
use std::thread;

fn main() {
    let counter = Mutex::new(0);

    let mut handles = vec![];

    for _ in 0..10 {
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Result: {}&quot;, *counter.lock().unwrap());
}</code></pre></pre>
<p>This code won't compile! The problem is that <code>counter</code> is moved into the first thread, leaving nothing for subsequent iterations. This is where <code>Arc</code> comes in.</p>
<h3 id="arc-atomic-reference-counting"><a class="header" href="#arc-atomic-reference-counting">Arc: Atomic Reference Counting</a></h3>
<p><code>Arc</code> (Atomic Reference Counting) provides shared ownership of a value across multiple threads. It's similar to <code>Rc</code>, but it uses atomic operations for its reference counting, making it thread-safe.</p>
<p>Let's fix our example:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter = Arc::clone(&amp;counter);
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Result: {}&quot;, *counter.lock().unwrap());
}</code></pre></pre>
<p>Now our code compiles and works correctly. <code>Arc</code> allows multiple threads to have shared ownership of the <code>Mutex</code>, and <code>Mutex</code> ensures that only one thread can access the value at a time.</p>
<h3 id="understanding-lock-and-poisoning"><a class="header" href="#understanding-lock-and-poisoning">Understanding lock() and Poisoning</a></h3>
<p>The <code>lock()</code> method on a <code>Mutex</code> returns a <code>LockResult&lt;MutexGuard&lt;T&gt;&gt;</code>. The <code>MutexGuard</code> is a smart pointer that automatically releases the lock when it goes out of scope.</p>
<p>If a thread panics while holding a <code>Mutex</code> lock, the mutex becomes &quot;poisoned.&quot; This means that future attempts to lock the mutex will return an error. This is a safety feature to prevent other threads from seeing inconsistent state:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));
    let counter_clone = Arc::clone(&amp;counter);

    let handle = thread::spawn(move || {
        let mut num = counter_clone.lock().unwrap();
        *num += 1;
        // This thread will panic
        panic!(&quot;Oh no!&quot;);
    });

    // Wait for the thread to finish or panic
    let _ = handle.join();

    // Trying to lock a poisoned mutex
    match counter.lock() {
        Ok(mut num) =&gt; {
            println!(&quot;Successfully acquired lock: {}&quot;, *num);
            *num += 1;
        }
        Err(poisoned) =&gt; {
            println!(&quot;Mutex is poisoned. Recovering...&quot;);
            let mut num = poisoned.into_inner();
            *num += 1;
            println!(&quot;Recovered value: {}&quot;, *num);
        }
    }
}</code></pre></pre>
<h3 id="rwlock-multiple-readers-or-single-writer"><a class="header" href="#rwlock-multiple-readers-or-single-writer">RwLock: Multiple Readers or Single Writer</a></h3>
<p>Sometimes, you want to allow multiple threads to read data simultaneously, but still ensure exclusive access for writing. <code>RwLock</code> (Reader-Writer Lock) provides this functionality:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{Arc, RwLock};
use std::thread;

fn main() {
    let data = Arc::new(RwLock::new(vec![1, 2, 3]));
    let mut handles = vec![];

    // Spawn some reader threads
    for i in 0..3 {
        let data = Arc::clone(&amp;data);
        let handle = thread::spawn(move || {
            let values = data.read().unwrap();
            println!(&quot;Reader {}: {:?}&quot;, i, *values);
        });
        handles.push(handle);
    }

    // Spawn a writer thread
    {
        let data = Arc::clone(&amp;data);
        let handle = thread::spawn(move || {
            let mut values = data.write().unwrap();
            values.push(4);
            println!(&quot;Writer: {:?}&quot;, *values);
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Final data: {:?}&quot;, *data.read().unwrap());
}</code></pre></pre>
<p><code>RwLock</code> allows any number of threads to hold a read lock simultaneously, but only one thread can hold a write lock, and no read locks can be held while a write lock is active.</p>
<h3 id="mutex-vs-rwlock-performance-considerations"><a class="header" href="#mutex-vs-rwlock-performance-considerations">Mutex vs RwLock Performance Considerations</a></h3>
<p>Choosing between <code>Mutex</code> and <code>RwLock</code> depends on your specific use case:</p>
<ul>
<li>
<p><strong><code>Mutex</code></strong>: Simpler and often has less overhead. Better when:</p>
<ul>
<li>Access patterns are write-heavy</li>
<li>Critical sections are very short</li>
<li>Contention is low</li>
</ul>
</li>
<li>
<p><strong><code>RwLock</code></strong>: More complex but allows concurrent reads. Better when:</p>
<ul>
<li>Access patterns are read-heavy</li>
<li>Multiple threads need to read simultaneously</li>
<li>Write operations are infrequent</li>
</ul>
</li>
</ul>
<p>Here's a simple benchmark:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{Arc, Mutex, RwLock};
use std::thread;
use std::time::{Duration, Instant};

fn main() {
    let iterations = 1_000_000;
    let read_percentage = 95; // 95% reads, 5% writes
    let num_threads = 8;

    benchmark_mutex(iterations, read_percentage, num_threads);
    benchmark_rwlock(iterations, read_percentage, num_threads);
}

fn benchmark_mutex(iterations: usize, read_percentage: usize, num_threads: usize) {
    let data = Arc::new(Mutex::new(0));
    let start = Instant::now();

    let mut handles = vec![];
    for _ in 0..num_threads {
        let data = Arc::clone(&amp;data);
        let handle = thread::spawn(move || {
            for i in 0..iterations / num_threads {
                if i % 100 &lt; read_percentage {
                    // Read operation
                    let _ = *data.lock().unwrap();
                } else {
                    // Write operation
                    let mut value = data.lock().unwrap();
                    *value += 1;
                }
            }
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Mutex: {:?}&quot;, start.elapsed());
}

fn benchmark_rwlock(iterations: usize, read_percentage: usize, num_threads: usize) {
    let data = Arc::new(RwLock::new(0));
    let start = Instant::now();

    let mut handles = vec![];
    for _ in 0..num_threads {
        let data = Arc::clone(&amp;data);
        let handle = thread::spawn(move || {
            for i in 0..iterations / num_threads {
                if i % 100 &lt; read_percentage {
                    // Read operation
                    let _ = *data.read().unwrap();
                } else {
                    // Write operation
                    let mut value = data.write().unwrap();
                    *value += 1;
                }
            }
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;RwLock: {:?}&quot;, start.elapsed());
}</code></pre></pre>
<h3 id="deadlocks-and-how-to-avoid-them"><a class="header" href="#deadlocks-and-how-to-avoid-them">Deadlocks and How to Avoid Them</a></h3>
<p>A deadlock occurs when two or more threads are blocked forever, each waiting for resources held by others. Here's a simple example of a deadlock:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{Arc, Mutex};
use std::thread;
use std::time::Duration;

fn main() {
    let mutex_a = Arc::new(Mutex::new(0));
    let mutex_b = Arc::new(Mutex::new(0));

    let mutex_a_clone = Arc::clone(&amp;mutex_a);
    let mutex_b_clone = Arc::clone(&amp;mutex_b);

    let thread_a = thread::spawn(move || {
        println!(&quot;Thread A: Trying to lock mutex A&quot;);
        let mut a = mutex_a_clone.lock().unwrap();
        println!(&quot;Thread A: Locked mutex A&quot;);

        thread::sleep(Duration::from_millis(100));

        println!(&quot;Thread A: Trying to lock mutex B&quot;);
        let mut b = mutex_b_clone.lock().unwrap();
        println!(&quot;Thread A: Locked mutex B&quot;);

        *a += 1;
        *b += 1;
    });

    let thread_b = thread::spawn(move || {
        println!(&quot;Thread B: Trying to lock mutex B&quot;);
        let mut b = mutex_b.lock().unwrap();
        println!(&quot;Thread B: Locked mutex B&quot;);

        thread::sleep(Duration::from_millis(100));

        println!(&quot;Thread B: Trying to lock mutex A&quot;);
        let mut a = mutex_a.lock().unwrap();
        println!(&quot;Thread B: Locked mutex A&quot;);

        *a += 1;
        *b += 1;
    });

    thread_a.join().unwrap();
    thread_b.join().unwrap();
}</code></pre></pre>
<p>This program will likely deadlock because:</p>
<ol>
<li>Thread A locks mutex A, then tries to lock mutex B</li>
<li>Simultaneously, Thread B locks mutex B, then tries to lock mutex A</li>
<li>Each thread is waiting for a lock that the other thread holds</li>
</ol>
<p>To avoid deadlocks:</p>
<ol>
<li><strong>Lock ordering</strong>: Always acquire locks in a consistent order</li>
<li><strong>Lock timeouts</strong>: Use methods like <code>try_lock_for</code> (available with the <code>parking_lot</code> crate)</li>
<li><strong>Avoid nested locks</strong>: Minimize the need to hold multiple locks at once</li>
<li><strong>Fine-grained locking</strong>: Use smaller, more focused locks instead of large, coarse-grained ones</li>
</ol>
<p>Here's the fixed version with consistent lock ordering:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{Arc, Mutex};
use std::thread;
use std::time::Duration;

fn main() {
    let mutex_a = Arc::new(Mutex::new(0));
    let mutex_b = Arc::new(Mutex::new(0));

    let mutex_a_clone = Arc::clone(&amp;mutex_a);
    let mutex_b_clone = Arc::clone(&amp;mutex_b);

    let thread_a = thread::spawn(move || {
        // Always lock mutex_a first, then mutex_b
        println!(&quot;Thread A: Trying to lock mutex A&quot;);
        let mut a = mutex_a_clone.lock().unwrap();
        println!(&quot;Thread A: Locked mutex A&quot;);

        thread::sleep(Duration::from_millis(100));

        println!(&quot;Thread A: Trying to lock mutex B&quot;);
        let mut b = mutex_b_clone.lock().unwrap();
        println!(&quot;Thread A: Locked mutex B&quot;);

        *a += 1;
        *b += 1;
    });

    let thread_b = thread::spawn(move || {
        // Also lock mutex_a first, then mutex_b
        println!(&quot;Thread B: Trying to lock mutex A&quot;);
        let mut a = mutex_a.lock().unwrap();
        println!(&quot;Thread B: Locked mutex A&quot;);

        thread::sleep(Duration::from_millis(100));

        println!(&quot;Thread B: Trying to lock mutex B&quot;);
        let mut b = mutex_b.lock().unwrap();
        println!(&quot;Thread B: Locked mutex B&quot;);

        *a += 1;
        *b += 1;
    });

    thread_a.join().unwrap();
    thread_b.join().unwrap();
}</code></pre></pre>
<h3 id="beyond-standard-library-parking_lot"><a class="header" href="#beyond-standard-library-parking_lot">Beyond Standard Library: parking_lot</a></h3>
<p>The standard library's synchronization primitives are robust and safe, but sometimes you need more features or better performance. The <code>parking_lot</code> crate provides alternative implementations of <code>Mutex</code>, <code>RwLock</code>, and other synchronization primitives:</p>
<pre><pre class="playground"><code class="language-rust">use parking_lot::{Mutex, RwLock};
use std::sync::Arc;
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter = Arc::clone(&amp;counter);
        let handle = thread::spawn(move || {
            // No unwrap needed - parking_lot's Mutex doesn't return a Result
            let mut num = counter.lock();
            *num += 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!(&quot;Result: {}&quot;, *counter.lock());
}</code></pre></pre>
<p>Advantages of <code>parking_lot</code> over standard library synchronization primitives:</p>
<ol>
<li><strong>Performance</strong>: Often faster, especially under contention</li>
<li><strong>No poisoning</strong>: Locks don't get poisoned when a thread panics</li>
<li><strong>More features</strong>: Timeouts, try-locking, and fair locks</li>
<li><strong>Smaller size</strong>: Takes up less memory</li>
</ol>
<h3 id="thread-local-storage-vs-shared-state"><a class="header" href="#thread-local-storage-vs-shared-state">Thread-Local Storage vs Shared State</a></h3>
<p>Sometimes, instead of sharing state between threads, it's better to give each thread its own local copy of the data. Rust provides thread-local storage via the <code>thread_local!</code> macro:</p>
<pre><pre class="playground"><code class="language-rust">use std::cell::RefCell;
use std::thread;

thread_local! {
    static COUNTER: RefCell&lt;u32&gt; = RefCell::new(0);
}

fn main() {
    // Each thread gets its own independent counter
    let handle1 = thread::spawn(|| {
        COUNTER.with(|counter| {
            *counter.borrow_mut() += 1;
            println!(&quot;Thread 1: {}&quot;, *counter.borrow());
        });
    });

    let handle2 = thread::spawn(|| {
        COUNTER.with(|counter| {
            *counter.borrow_mut() += 1;
            println!(&quot;Thread 2: {}&quot;, *counter.borrow());
        });
    });

    handle1.join().unwrap();
    handle2.join().unwrap();

    COUNTER.with(|counter| {
        println!(&quot;Main thread: {}&quot;, *counter.borrow());
    });
}</code></pre></pre>
<p>In this example, each thread gets its own independent counter, so there's no need for synchronization.</p>
<h3 id="choosing-between-sharing-strategies"><a class="header" href="#choosing-between-sharing-strategies">Choosing Between Sharing Strategies</a></h3>
<p>When designing concurrent systems, you have several options for handling shared state:</p>
<ol>
<li>
<p><strong>Thread-local storage</strong>: Each thread has its own copy</p>
<ul>
<li>Pros: No synchronization needed, very fast</li>
<li>Cons: Data isn't shared, may need to combine results later</li>
</ul>
</li>
<li>
<p><strong>Message passing</strong>: Threads communicate by sending messages</p>
<ul>
<li>Pros: Clear ownership, less chance of deadlocks</li>
<li>Cons: May require copying data</li>
</ul>
</li>
<li>
<p><strong>Shared state with synchronization</strong>: Threads access the same data with locks</p>
<ul>
<li>Pros: Direct access to shared data, no copying needed</li>
<li>Cons: Risk of deadlocks, potential contention</li>
</ul>
</li>
</ol>
<p>Choose the approach that best fits your specific use case, considering factors like data size, access patterns, and performance requirements.</p>
<h2 id="channels-and-message-passing"><a class="header" href="#channels-and-message-passing">Channels and Message Passing</a></h2>
<p>While sharing state with synchronization primitives like <code>Mutex</code> and <code>Arc</code> is powerful, an alternative approach to concurrency is message passing. Instead of sharing memory, threads communicate by sending messages to each other. This paradigm is summed up by the saying: &quot;Do not communicate by sharing memory; instead, share memory by communicating.&quot;</p>
<h3 id="basic-channel-operations"><a class="header" href="#basic-channel-operations">Basic Channel Operations</a></h3>
<p>Rust provides channels through the <code>std::sync::mpsc</code> module, where &quot;mpsc&quot; stands for &quot;multiple producer, single consumer&quot;. This means that multiple threads can send messages, but only one thread can receive them.</p>
<p>Here's a basic example:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::mpsc;
use std::thread;

fn main() {
    // Create a channel
    let (tx, rx) = mpsc::channel();

    // Spawn a thread that will send a message
    thread::spawn(move || {
        // Send a message
        tx.send(&quot;Hello from another thread!&quot;).unwrap();
    });

    // Receive the message in the main thread
    let message = rx.recv().unwrap();
    println!(&quot;Received: {}&quot;, message);
}</code></pre></pre>
<p>In this example, we create a channel with <code>mpsc::channel()</code>, which returns a tuple containing a sender (<code>tx</code>) and a receiver (<code>rx</code>). We then spawn a thread that sends a message through the channel, and the main thread receives it.</p>
<h3 id="multiple-producers"><a class="header" href="#multiple-producers">Multiple Producers</a></h3>
<p>The &quot;mp&quot; in &quot;mpsc&quot; means that multiple threads can send messages through the same channel. Let's see how this works:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    // Create a channel
    let (tx, rx) = mpsc::channel();

    // Clone the sender for multiple producer threads
    let tx1 = tx.clone();
    let tx2 = tx.clone();

    // Spawn thread 1
    thread::spawn(move || {
        tx1.send(&quot;Hello from thread 1&quot;).unwrap();
        thread::sleep(Duration::from_millis(100));
        tx1.send(&quot;Thread 1 again&quot;).unwrap();
    });

    // Spawn thread 2
    thread::spawn(move || {
        thread::sleep(Duration::from_millis(50));
        tx2.send(&quot;Hello from thread 2&quot;).unwrap();
        thread::sleep(Duration::from_millis(100));
        tx2.send(&quot;Thread 2 again&quot;).unwrap();
    });

    // Original sender in the main thread
    tx.send(&quot;Hello from main thread&quot;).unwrap();

    // Drop the original sender to ensure proper cleanup
    drop(tx);

    // Receive all messages
    for message in rx {
        println!(&quot;Received: {}&quot;, message);
    }
}</code></pre></pre>
<p>By cloning the sender (<code>tx</code>), we can have multiple threads sending messages through the same channel.</p>
<h3 id="synchronous-vs-asynchronous-channels"><a class="header" href="#synchronous-vs-asynchronous-channels">Synchronous vs. Asynchronous Channels</a></h3>
<p>The standard <code>mpsc::channel()</code> is asynchronous, meaning the sender doesn't wait for the receiver to process the message. Rust also provides a synchronous channel with <code>mpsc::sync_channel()</code>, which has a bounded buffer:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    // Create a synchronous channel with a buffer of 2 messages
    let (tx, rx) = mpsc::sync_channel(2);

    thread::spawn(move || {
        println!(&quot;Sending message 1&quot;);
        tx.send(1).unwrap();

        println!(&quot;Sending message 2&quot;);
        tx.send(2).unwrap();

        println!(&quot;Sending message 3 (this will block until a message is received)&quot;);
        tx.send(3).unwrap();

        println!(&quot;Message 3 was received, continuing...&quot;);
        tx.send(4).unwrap();

        println!(&quot;All messages sent&quot;);
    });

    // Simulate a slow receiver
    thread::sleep(Duration::from_secs(2));

    for message in rx {
        println!(&quot;Received: {}&quot;, message);
        thread::sleep(Duration::from_millis(500));
    }
}</code></pre></pre>
<p>In this example, the sender will block after sending the third message until the receiver has processed at least one message, freeing up space in the buffer.</p>
<h3 id="transferring-ownership-through-channels"><a class="header" href="#transferring-ownership-through-channels">Transferring Ownership Through Channels</a></h3>
<p>Channels transfer ownership of the sent values from the sender to the receiver. This makes them an excellent way to safely share data between threads:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::mpsc;
use std::thread;

fn main() {
    let (tx, rx) = mpsc::channel();

    thread::spawn(move || {
        // Create a string in this thread
        let message = String::from(&quot;Hello from another thread&quot;);

        // Send ownership of the string to the receiver
        tx.send(message).unwrap();

        // We can no longer use message here because ownership was transferred
        // println!(&quot;After sending: {}&quot;, message); // This would cause a compilation error
    });

    // Receive ownership of the string
    let received = rx.recv().unwrap();
    println!(&quot;Received: {}&quot;, received);
}</code></pre></pre>
<p>This ownership transfer ensures that only one thread has access to the data at a time, preventing data races.</p>
<h3 id="error-handling-with-channels"><a class="header" href="#error-handling-with-channels">Error Handling with Channels</a></h3>
<p>When using channels, there are two main types of errors to handle:</p>
<ol>
<li><strong>Send errors</strong>: Occur when the receiver has been dropped</li>
<li><strong>Receive errors</strong>: Occur when all senders have been dropped</li>
</ol>
<pre><pre class="playground"><code class="language-rust">use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();

    let handle = thread::spawn(move || {
        // Wait a bit before trying to send
        thread::sleep(Duration::from_secs(1));

        // At this point, the receiver might have been dropped
        match tx.send(&quot;Hello&quot;) {
            Ok(()) =&gt; println!(&quot;Message sent successfully&quot;),
            Err(e) =&gt; println!(&quot;Failed to send: {}&quot;, e),
        }
    });

    // Simulate the receiver being dropped
    drop(rx);

    handle.join().unwrap();

    // -------------------

    let (tx, rx) = mpsc::channel::&lt;String&gt;();

    // Drop the sender without sending anything
    drop(tx);

    // Now try to receive
    match rx.recv() {
        Ok(msg) =&gt; println!(&quot;Received: {}&quot;, msg),
        Err(e) =&gt; println!(&quot;Failed to receive: {}&quot;, e),
    }
}</code></pre></pre>
<h2 id="thread-pools"><a class="header" href="#thread-pools">Thread Pools</a></h2>
<p>Creating a new thread for every task can be inefficient, especially for short-lived tasks. Thread pools solve this problem by maintaining a set of worker threads that are reused for multiple tasks.</p>
<h3 id="why-use-thread-pools"><a class="header" href="#why-use-thread-pools">Why Use Thread Pools?</a></h3>
<p>Thread pools offer several advantages:</p>
<ol>
<li><strong>Reduced overhead</strong>: Thread creation and destruction is expensive</li>
<li><strong>Controlled concurrency</strong>: Limit the number of concurrent tasks</li>
<li><strong>Load balancing</strong>: Distribute work across available threads</li>
<li><strong>Resource management</strong>: Prevent thread exhaustion</li>
</ol>
<h3 id="basic-thread-pool-implementation"><a class="header" href="#basic-thread-pool-implementation">Basic Thread Pool Implementation</a></h3>
<p>Let's implement a simple thread pool to understand the core concepts:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::{mpsc, Arc, Mutex};
use std::thread;

struct ThreadPool {
    workers: Vec&lt;Worker&gt;,
    sender: Option&lt;mpsc::Sender&lt;Job&gt;&gt;,
}

type Job = Box&lt;dyn FnOnce() + Send + 'static&gt;;

impl ThreadPool {
    fn new(size: usize) -&gt; ThreadPool {
        assert!(size &gt; 0);

        let (sender, receiver) = mpsc::channel();
        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&amp;receiver)));
        }

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }

    fn execute&lt;F&gt;(&amp;self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&amp;mut self) {
        drop(self.sender.take());

        for worker in &amp;mut self.workers {
            println!(&quot;Shutting down worker {}&quot;, worker.id);

            if let Some(thread) = worker.thread.take() {
                thread.join().unwrap();
            }
        }
    }
}

struct Worker {
    id: usize,
    thread: Option&lt;thread::JoinHandle&lt;()&gt;&gt;,
}

impl Worker {
    fn new(id: usize, receiver: Arc&lt;Mutex&lt;mpsc::Receiver&lt;Job&gt;&gt;&gt;) -&gt; Worker {
        let thread = thread::spawn(move || loop {
            let message = receiver.lock().unwrap().recv();

            match message {
                Ok(job) =&gt; {
                    println!(&quot;Worker {}: got a job; executing.&quot;, id);
                    job();
                }
                Err(_) =&gt; {
                    println!(&quot;Worker {}: disconnected; shutting down.&quot;, id);
                    break;
                }
            }
        });

        Worker {
            id,
            thread: Some(thread),
        }
    }
}

fn main() {
    let pool = ThreadPool::new(4);

    for i in 0..8 {
        pool.execute(move || {
            println!(&quot;Processing task {}&quot;, i);
            thread::sleep(std::time::Duration::from_secs(1));
            println!(&quot;Task {} completed&quot;, i);
        });
    }

    // The pool will be dropped at the end of main, which will
    // shut down all workers gracefully.
    println!(&quot;All tasks submitted&quot;);
}</code></pre></pre>
<p>This thread pool creates a fixed number of worker threads and distributes jobs among them using a channel.</p>
<h2 id="parallel-iterators"><a class="header" href="#parallel-iterators">Parallel Iterators</a></h2>
<p>Parallel iterators are one of the most powerful tools for writing concurrent code in Rust. They allow you to perform operations on collections in parallel with minimal effort.</p>
<h3 id="introduction-to-parallel-iterators"><a class="header" href="#introduction-to-parallel-iterators">Introduction to Parallel Iterators</a></h3>
<p>The <code>rayon</code> crate provides parallel versions of Rust's standard iterators. The main entry points are:</p>
<ul>
<li><code>par_iter()</code>: Parallel immutable iterator</li>
<li><code>par_iter_mut()</code>: Parallel mutable iterator</li>
<li><code>into_par_iter()</code>: Parallel iterator that consumes the collection</li>
</ul>
<p>Let's see a basic example:</p>
<pre><pre class="playground"><code class="language-rust">use rayon::prelude::*;

fn main() {
    let v = vec![1, 2, 3, 4, 5, 6, 7, 8];

    // Sequential map and filter
    let sum_sequential: i32 = v.iter()
        .map(|&amp;x| x * x)
        .filter(|&amp;x| x % 2 == 0)
        .sum();

    // Parallel map and filter
    let sum_parallel: i32 = v.par_iter()
        .map(|&amp;x| x * x)
        .filter(|&amp;x| x % 2 == 0)
        .sum();

    println!(&quot;Sequential sum: {}&quot;, sum_sequential);
    println!(&quot;Parallel sum: {}&quot;, sum_parallel);
    assert_eq!(sum_sequential, sum_parallel);
}</code></pre></pre>
<p>By changing <code>iter()</code> to <code>par_iter()</code>, we make the computation parallel with minimal code changes.</p>
<h3 id="common-parallel-iterator-operations"><a class="header" href="#common-parallel-iterator-operations">Common Parallel Iterator Operations</a></h3>
<p>Parallel iterators support most of the operations that sequential iterators do:</p>
<pre><pre class="playground"><code class="language-rust">use rayon::prelude::*;

fn main() {
    let v = vec![1, 2, 3, 4, 5];

    // Parallel map
    let squares: Vec&lt;i32&gt; = v.par_iter().map(|&amp;x| x * x).collect();
    println!(&quot;Squares: {:?}&quot;, squares);

    // Parallel filter
    let evens: Vec&lt;i32&gt; = v.par_iter().filter(|&amp;&amp;x| x % 2 == 0).cloned().collect();
    println!(&quot;Evens: {:?}&quot;, evens);

    // Parallel fold (similar to reduce)
    let sum = v.par_iter().fold(|| 0, |acc, &amp;x| acc + x);
    println!(&quot;Sum: {}&quot;, sum);

    // Parallel reduce
    let product = v.par_iter()
        .cloned()
        .reduce(|| 1, |a, b| a * b);
    println!(&quot;Product: {}&quot;, product);

    // Parallel for_each
    v.par_iter().for_each(|&amp;x| {
        println!(&quot;Processing: {}&quot;, x);
    });
}</code></pre></pre>
<h3 id="comparing-sequential-and-parallel-performance"><a class="header" href="#comparing-sequential-and-parallel-performance">Comparing Sequential and Parallel Performance</a></h3>
<p>Let's benchmark parallel iterators against sequential ones:</p>
<pre><pre class="playground"><code class="language-rust">use rayon::prelude::*;
use std::time::Instant;

fn main() {
    let size = 10_000_000;
    let v: Vec&lt;i32&gt; = (0..size).collect();

    // Warm-up
    let _ = v.iter().map(|&amp;x| x * x).sum::&lt;i64&gt;();
    let _ = v.par_iter().map(|&amp;x| x * x).sum::&lt;i64&gt;();

    // Benchmark sequential
    let start = Instant::now();
    let sum_sequential: i64 = v.iter().map(|&amp;x| x * x).sum();
    let sequential_time = start.elapsed();
    println!(&quot;Sequential: {:?}&quot;, sequential_time);

    // Benchmark parallel
    let start = Instant::now();
    let sum_parallel: i64 = v.par_iter().map(|&amp;x| x * x).sum();
    let parallel_time = start.elapsed();
    println!(&quot;Parallel: {:?}&quot;, parallel_time);

    println!(&quot;Speedup: {:.2}x&quot;, sequential_time.as_secs_f64() / parallel_time.as_secs_f64());
    assert_eq!(sum_sequential, sum_parallel);
}</code></pre></pre>
<p>The speedup you'll see depends on:</p>
<ol>
<li>The number of cores in your system</li>
<li>The complexity of the computation</li>
<li>The size of the data</li>
<li>The overhead of parallelization</li>
</ol>
<h2 id="project-parallel-web-scraper"><a class="header" href="#project-parallel-web-scraper">Project: Parallel Web Scraper</a></h2>
<p>Let's apply what we've learned to build a practical project—a parallel web scraper that fetches and processes multiple web pages simultaneously.</p>
<h3 id="project-outline"><a class="header" href="#project-outline">Project Outline</a></h3>
<p>Our web scraper will:</p>
<ol>
<li>Take a list of URLs as input</li>
<li>Fetch the content of each URL in parallel</li>
<li>Extract relevant information (like title and links)</li>
<li>Save the results to a file</li>
</ol>
<h3 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h3>
<p>First, let's define the dependencies we'll need in our <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
reqwest = { version = &quot;0.11&quot;, features = [&quot;blocking&quot;] }
rayon = &quot;1.5&quot;
scraper = &quot;0.13&quot;
url = &quot;2.2&quot;
anyhow = &quot;1.0&quot;
</code></pre>
<h3 id="basic-structure"><a class="header" href="#basic-structure">Basic Structure</a></h3>
<p>Here's the implementation of our parallel web scraper:</p>
<pre><pre class="playground"><code class="language-rust">use anyhow::{Context, Result};
use rayon::prelude::*;
use reqwest::blocking::Client;
use scraper::{Html, Selector};
use std::collections::HashSet;
use std::fs::File;
use std::io::Write;
use std::sync::{Arc, Mutex};
use std::time::Instant;
use url::Url;

// Structure to hold scraped data for a page
#[derive(Debug)]
struct PageData {
    url: String,
    title: String,
    links: Vec&lt;String&gt;,
}

// Fetch and parse a single URL
fn scrape_url(client: &amp;Client, url: &amp;str) -&gt; Result&lt;PageData&gt; {
    println!(&quot;Fetching: {}&quot;, url);

    // Fetch the page content
    let response = client.get(url).send()
        .with_context(|| format!(&quot;Failed to fetch {}&quot;, url))?;

    let status = response.status();
    if !status.is_success() {
        anyhow::bail!(&quot;Failed to fetch {}: {}&quot;, url, status);
    }

    let content = response.text()
        .with_context(|| format!(&quot;Failed to read content from {}&quot;, url))?;

    // Parse the HTML
    let document = Html::parse_document(&amp;content);

    // Extract the title
    let title_selector = Selector::parse(&quot;title&quot;).unwrap();
    let title = document.select(&amp;title_selector)
        .next()
        .map(|element| element.text().collect::&lt;Vec&lt;_&gt;&gt;().join(&quot;&quot;))
        .unwrap_or_else(|| &quot;No title&quot;.to_string());

    // Extract links
    let link_selector = Selector::parse(&quot;a[href]&quot;).unwrap();
    let base_url = Url::parse(url)?;

    let mut links = Vec::new();
    for element in document.select(&amp;link_selector) {
        if let Some(href) = element.value().attr(&quot;href&quot;) {
            if let Ok(absolute_url) = base_url.join(href) {
                links.push(absolute_url.to_string());
            }
        }
    }

    Ok(PageData {
        url: url.to_string(),
        title,
        links,
    })
}

// Main function to scrape multiple URLs in parallel
fn parallel_scrape(urls: Vec&lt;String&gt;) -&gt; Result&lt;Vec&lt;PageData&gt;&gt; {
    // Create a shared HTTP client
    let client = Client::new();

    // Use a mutex to collect errors from parallel tasks
    let errors = Arc::new(Mutex::new(Vec::new()));

    // Scrape URLs in parallel
    let results: Vec&lt;Option&lt;PageData&gt;&gt; = urls.par_iter()
        .map(|url| {
            match scrape_url(&amp;client, url) {
                Ok(data) =&gt; Some(data),
                Err(err) =&gt; {
                    let mut errors = errors.lock().unwrap();
                    errors.push(format!(&quot;Error scraping {}: {}&quot;, url, err));
                    None
                }
            }
        })
        .collect();

    // Report any errors
    let errors = errors.lock().unwrap();
    for error in errors.iter() {
        eprintln!(&quot;{}&quot;, error);
    }

    // Filter out None values (failed scrapes)
    let results: Vec&lt;PageData&gt; = results.into_iter()
        .filter_map(|x| x)
        .collect();

    Ok(results)
}

// Save the scraped data to a file
fn save_results(results: &amp;[PageData], filename: &amp;str) -&gt; Result&lt;()&gt; {
    let mut file = File::create(filename)
        .with_context(|| format!(&quot;Failed to create file: {}&quot;, filename))?;

    for page in results {
        writeln!(file, &quot;URL: {}&quot;, page.url)?;
        writeln!(file, &quot;Title: {}&quot;, page.title)?;
        writeln!(file, &quot;Links: {}&quot;, page.links.len())?;

        for link in &amp;page.links {
            writeln!(file, &quot;  - {}&quot;, link)?;
        }

        writeln!(file)?;
    }

    Ok(())
}

// Find unique domains in the scraped data
fn find_unique_domains(results: &amp;[PageData]) -&gt; HashSet&lt;String&gt; {
    let mut domains = HashSet::new();

    for page in results {
        if let Ok(url) = Url::parse(&amp;page.url) {
            if let Some(domain) = url.host_str() {
                domains.insert(domain.to_string());
            }
        }

        for link in &amp;page.links {
            if let Ok(url) = Url::parse(link) {
                if let Some(domain) = url.host_str() {
                    domains.insert(domain.to_string());
                }
            }
        }
    }

    domains
}

fn main() -&gt; Result&lt;()&gt; {
    // List of URLs to scrape
    let urls = vec![
        &quot;https://www.rust-lang.org&quot;.to_string(),
        &quot;https://blog.rust-lang.org&quot;.to_string(),
        &quot;https://crates.io&quot;.to_string(),
        &quot;https://doc.rust-lang.org&quot;.to_string(),
        &quot;https://www.github.com/rust-lang/rust&quot;.to_string(),
    ];

    println!(&quot;Starting parallel web scraper...&quot;);
    let start = Instant::now();

    // Perform the parallel scrape
    let results = parallel_scrape(urls)?;

    let elapsed = start.elapsed();
    println!(&quot;Scraped {} pages in {:.2?}&quot;, results.len(), elapsed);

    // Save results to a file
    save_results(&amp;results, &quot;scrape_results.txt&quot;)?;

    // Find and display unique domains
    let domains = find_unique_domains(&amp;results);
    println!(&quot;Found {} unique domains:&quot;, domains.len());
    for domain in domains {
        println!(&quot;  - {}&quot;, domain);
    }

    Ok(())
}</code></pre></pre>
<h3 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h3>
<ol>
<li>We use <code>rayon</code> for parallel processing of URLs</li>
<li><code>reqwest</code> handles the HTTP requests</li>
<li><code>scraper</code> parses the HTML content</li>
<li>We use a thread-safe error collection mechanism with <code>Arc&lt;Mutex&lt;Vec&lt;String&gt;&gt;&gt;</code></li>
<li>The scraper extracts titles and links from each page</li>
<li>Results are saved to a file and statistics are displayed</li>
</ol>
<h3 id="extending-the-project"><a class="header" href="#extending-the-project">Extending the Project</a></h3>
<p>Here are some ways you could extend this web scraper:</p>
<ol>
<li><strong>Add depth control</strong>: Implement recursive crawling with a maximum depth</li>
<li><strong>Respect robots.txt</strong>: Add a parser for robots.txt to avoid scraping disallowed pages</li>
<li><strong>Add rate limiting</strong>: Implement delays between requests to the same domain</li>
<li><strong>Improve error handling</strong>: Add retries for failed requests</li>
<li><strong>Add more extractors</strong>: Extract additional information like meta tags, images, etc.</li>
<li><strong>Use async/await</strong>: Convert to asynchronous code for potentially better performance</li>
</ol>
<p>This project demonstrates how to use Rust's concurrency features for a real-world task, combining threads, synchronization, and parallel iterators to efficiently process multiple web pages.</p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>In this chapter, we've explored Rust's approach to concurrency, which combines powerful primitives with compile-time safety guarantees. We've covered:</p>
<ol>
<li><strong>Concurrency vs. Parallelism</strong>: Understanding the difference between structure (concurrency) and execution (parallelism)</li>
<li><strong>Threads</strong>: Creating and managing threads with <code>std::thread</code></li>
<li><strong>Thread Safety</strong>: How Rust's type system prevents data races with <code>Send</code> and <code>Sync</code> traits</li>
<li><strong>Race Conditions</strong>: Understanding and preventing more subtle concurrency bugs</li>
<li><strong>Sharing State</strong>: Using <code>Mutex</code>, <code>RwLock</code>, and <code>Arc</code> for safe shared access</li>
<li><strong>Message Passing</strong>: Using channels for communication between threads</li>
<li><strong>Thread Pools</strong>: Managing groups of worker threads for efficient task execution</li>
<li><strong>Parallel Iterators</strong>: Processing collections in parallel with minimal code changes</li>
</ol>
<p>Rust's approach to concurrency is unique among programming languages. Rather than relying on runtime checks or programmer discipline, it leverages the type system to prevent many common concurrency bugs at compile time. This &quot;fearless concurrency&quot; allows you to write concurrent code with confidence, knowing that the compiler has your back.</p>
<p>As you build concurrent systems in Rust, remember these key principles:</p>
<ol>
<li><strong>Be explicit about sharing</strong>: Use the appropriate synchronization primitives when sharing data</li>
<li><strong>Consider message passing</strong>: Often simpler and less error-prone than shared state</li>
<li><strong>Use high-level abstractions</strong>: Libraries like <code>rayon</code> make parallelism accessible</li>
<li><strong>Measure performance</strong>: Don't assume parallelism always improves performance</li>
<li><strong>Mind the cost of synchronization</strong>: Locking and thread coordination have overhead</li>
</ol>
<p>With these tools and principles, you're well-equipped to write safe, efficient concurrent code in Rust.</p>
<h2 id="exercises"><a class="header" href="#exercises">Exercises</a></h2>
<ol>
<li>
<p><strong>Channel Calculator</strong>: Implement a calculator where operations are sent through channels to worker threads, with results returned through another channel.</p>
</li>
<li>
<p><strong>Thread-safe Counter</strong>: Create a counter that can be safely incremented from multiple threads, then implement versions using <code>Mutex</code>, <code>atomic</code>, and a channel-based approach. Compare their performance.</p>
</li>
<li>
<p><strong>Parallel File Processor</strong>: Write a program that processes multiple files in parallel, calculating statistics like word count, line count, and character frequencies.</p>
</li>
<li>
<p><strong>Custom Thread Pool</strong>: Extend the thread pool implementation with features like task priorities, task cancellation, and worker thread statistics.</p>
</li>
<li>
<p><strong>Parallel Merge Sort</strong>: Implement a parallel version of the merge sort algorithm using <code>rayon</code>.</p>
</li>
<li>
<p><strong>Web API Aggregator</strong>: Create a program that fetches data from multiple API endpoints in parallel and combines the results.</p>
</li>
<li>
<p><strong>Parallel Image Processing</strong>: Write a program that applies filters to images in parallel, using a thread for each region of the image.</p>
</li>
<li>
<p><strong>Concurrent Map</strong>: Implement a thread-safe map data structure that allows concurrent reads and writes.</p>
</li>
<li>
<p><strong>Lock-free Stack</strong>: Implement a lock-free stack using atomic operations.</p>
</li>
<li>
<p><strong>Parallel Graph Algorithm</strong>: Implement a parallel graph traversal algorithm like breadth-first search.</p>
</li>
</ol>
<h2 id="further-reading"><a class="header" href="#further-reading">Further Reading</a></h2>
<ul>
<li><a href="https://doc.rust-lang.org/book/ch16-00-concurrency.html">The Rust Programming Language - Fearless Concurrency</a></li>
<li><a href="https://doc.rust-lang.org/rust-by-example/std_misc/threads.html">Rust By Example - Concurrency</a></li>
<li><a href="https://docs.rs/rayon/">The Rayon Crate Documentation</a></li>
<li><a href="https://docs.rs/parking_lot/">The Parking Lot Crate Documentation</a></li>
<li><a href="https://www.oreilly.com/library/view/programming-rust-2nd/9781492052586/">Programming Rust - O'Reilly book with excellent coverage of concurrency</a></li>
<li><a href="https://marabos.nl/atomics/">Rust Atomics and Locks - Jon Gjengset's book on low-level concurrency</a></li>
<li><a href="https://docs.rs/crossbeam/">Crossbeam Documentation</a> - Advanced concurrency primitives</li>
<li><a href="https://docs.rs/tokio/">Tokio Documentation</a> - Asynchronous runtime for Rust</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapters/23-closures.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapters/25-async.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapters/23-closures.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapters/25-async.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
